{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import interpolate\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.misc import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_historical_diagram():\n",
    "    '''\n",
    "    do all of the stuff for the graphics of making a hurricane plot\n",
    "    \n",
    "    takes in the year dataframe in order to get the necessary data\n",
    "    \n",
    "    returns ax which is the figure axis that the current hurricane track will be added upon\n",
    "    '''\n",
    "    # establish the figure\n",
    "    figure = plt.figure(figsize=(19.2, 12.0), dpi=100)\n",
    "    \n",
    "    axis = figure.add_subplot(111)\n",
    "    axis.set_facecolor(\"#000000\")\n",
    "    \n",
    "#     figure, axis = plt.subplots(figsize=(19.2,12.00), dpi=100)\n",
    "    \n",
    "#     data = np.linspace(165.0, 0, 10000).reshape(100,100)\n",
    "# #     data = np.clip(randn(250, 250), -1, 1)\n",
    "\n",
    "#     histo_image = axis.imshow(data, interpolation='nearest', cmap=\"inferno\")\n",
    "    \n",
    "#     divider = make_axes_locatable(axis)\n",
    "    \n",
    "#     cax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)\n",
    "\n",
    "#     # Add colorbar, make sure to specify tick locations to match desired ticklabels\n",
    "#     cbar = figure.colorbar(histo_image, ticks=[157, 130, 111, 96, 74, 39, 0], cax=cax)\n",
    "#     cbar.ax.set_yticklabels(['5^', '4^', '3^', '2^', '1^', 'T.S.^', 'T.D.^'])  # vertically oriented colorbar\n",
    "#     axis.set_title(\"North American Hurricane Tracks \" + str(_year), size=20)\n",
    "#     axis.set_xlabel(\"Longitude\", size=16)\n",
    "#     axis.set_ylabel(\"Latitude\", size=16)\n",
    "#     axis.set_facecolor(\"black\")\n",
    "    axis.set_xlim(-120.0, -30.0)\n",
    "    axis.set_ylim(10, 50.0)\n",
    "    \n",
    "    return figure, axis\n",
    "    \n",
    "def heatmap(ax, storm):\n",
    "    '''\n",
    "    make a heatmap of storm track?\n",
    "    '''\n",
    "    x, y = storm_heat(storm)\n",
    "    \n",
    "    ax.hexbin(x, y, gridsize=50, bins=\"log\", cmap=\"inferno\")\n",
    "    \n",
    "    # ax.hexbin(x, y, gridsize=50, bins='log', cmap='inferno')\n",
    "    \n",
    "def storm_heat(storm):\n",
    "    '''\n",
    "    make storm track into two lists that will be turned into a heatmap\n",
    "    '''\n",
    "    _x = []\n",
    "    _y = []\n",
    "    \n",
    "    if len(storm) >= 5:\n",
    "        interpolation_multiplier = 120\n",
    "\n",
    "        _lat = storm.Latitude.apply(lambda x: float(x))\n",
    "        _long = storm.Longitude.apply(lambda x: float(x))\n",
    "\n",
    "#         _strengths = storm.loc[:,\"Wind(WMO)\"].apply(lambda x: int(((x / 165.0) * 5.0)**2))\n",
    "        \n",
    "        # since the 'saffir_simpson_cat' column ranges from -1 to 5 add 2 to it\n",
    "        # so that the range is 1 <-> 7 which a computer understands better\n",
    "        _strengths = storm.loc[:, \"saffir_simpson_cat\"].apply(lambda x: int((x + 2)**2))\n",
    "        \n",
    "        new_length = interpolation_multiplier * len(_lat)\n",
    "\n",
    "        x = np.arange(len(_lat))\n",
    "\n",
    "        # figure out length of new arrays\n",
    "        new_x = np.linspace(x.min(), x.max(), new_length)\n",
    "\n",
    "        # actually do the interpolation\n",
    "        new_lat = interpolate.interp1d(x, _lat, kind='cubic')(new_x)\n",
    "        new_long = interpolate.interp1d(x, _long, kind='cubic')(new_x)\n",
    "        new_strs = interpolate.interp1d(x, _strengths, kind='cubic')(new_x)\n",
    "        \n",
    "        for idx in range(len(new_lat)):\n",
    "            _strength = int(new_strs[idx])\n",
    "            for idy in range(_strength):\n",
    "                _x.append(new_long[idx])\n",
    "                _y.append(new_lat[idx])\n",
    "\n",
    "    return _x, _y\n",
    "\n",
    "def safsimpsonize(wind):\n",
    "    '''\n",
    "    Takes in wind speed\n",
    "    \n",
    "    Returns saffir-simpson hurricane category with 0 and -1 for tropical storm/depression\n",
    "    which doesn't make perfect sense as scales go but this maintains categories but allows\n",
    "    the model/visualization to detect when something is a tropical depression\n",
    "    \n",
    "    According to: https://en.wikipedia.org/wiki/Saffir%E2%80%93Simpson_scale\n",
    "    \n",
    "    Return:  Category:   Wind Speed Range: (mph, seriously?)\n",
    "    5        Cat 5      157 <= v\n",
    "    4        Cat 4      130 <= v < 157\n",
    "    3        Cat 3      111 <= v < 130\n",
    "    2        Cat 2      96 <= v < 111\n",
    "    1        Cat 1      74 <= v < 96\n",
    "    0        Storm      39 <= v < 74\n",
    "    -1       Depression v < 39\n",
    "    '''\n",
    "    if wind >= 157:\n",
    "        return 5\n",
    "    elif wind >= 130:\n",
    "        return 4\n",
    "    elif wind >= 111:\n",
    "        return 3\n",
    "    elif wind >= 96:\n",
    "        return 2\n",
    "    elif wind >= 74:\n",
    "        return 1\n",
    "    elif wind >= 39:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def load_hurricane_data(_path=\"../data/allstorms.csv\"):\n",
    "    data = pd.read_csv(_path)\n",
    "\n",
    "    # data dictionary\n",
    "    # N/A,Year,#,BB,BB,N/A,YYYY-MM-DD HH:MM:SS,N/A,deg_north,deg_east,kt,mb,N/A,%,%,N/A\n",
    "\n",
    "    data.loc[:,\"Season\"] = data.loc[:,\"Season\"].apply(lambda x: int(x))\n",
    "\n",
    "#     print data.loc[:,\"Basin\"].unique()\n",
    "    # array(['BB', ' SI', ' NA', ' EP', ' SP', ' WP', ' NI', ' SA'], dtype=object)\n",
    "\n",
    "    data.loc[:, \"Basin\"] = data.loc[:, \"Basin\"].apply(lambda x: x.replace(\" \", \"\"))\n",
    "\n",
    "#     print data.loc[:,\"Basin\"].unique()\n",
    "    # ['BB' 'SI' 'NA' 'EP' 'SP' 'WP' 'NI' 'SA']\n",
    "\n",
    "    data_na = data[data.loc[:, \"Basin\"] == \"NA\"]\n",
    "    \n",
    "    data_na.loc[:,\"saffir_simpson_cat\"] = data_na[\"Wind(WMO)\"].apply(lambda x: safsimpsonize(x))\n",
    "\n",
    "    # try to give back memory\n",
    "    del data\n",
    "    \n",
    "    return data_na\n",
    "\n",
    "def get_data_as_yearlist(start_year, end_year):\n",
    "    '''\n",
    "    take in data frame (north atlantic most likely) and turn it into a list of dataframes\n",
    "    with each entry being a dataframe holding a year's data\n",
    "    '''\n",
    "    # load data frame that we want\n",
    "    data_na = load_hurricane_data()\n",
    "    \n",
    "    # make a list for the years\n",
    "    years = []\n",
    "\n",
    "    # step through the Seasons (years) and make a new dataframe for each one\n",
    "    for year in data_na.loc[:, \"Season\"].unique():\n",
    "        temp = data_na[data_na.loc[:, \"Season\"] == year]\n",
    "        years.append(temp)\n",
    "\n",
    "    # get rid of a nan DataFrame\n",
    "    years.pop(0)\n",
    "\n",
    "    #loop through years in future gif\n",
    "    start = 164 - (2016 - start_year)\n",
    "    end = 164 - (2016 - end_year)\n",
    "    \n",
    "    if start != end:\n",
    "        temp = years[start:end]\n",
    "    else:\n",
    "        # handle case where only one year is wanted\n",
    "        temp = []\n",
    "        temp.append(years[start])\n",
    "    \n",
    "    # try to give back memory\n",
    "    del years\n",
    "    \n",
    "    return temp\n",
    "\n",
    "def get_storms_from_year(year_df):\n",
    "    '''\n",
    "    year_df is the dataframe with a year's data\n",
    "    \n",
    "    returns a list of smaller dataframes each consisting of a \n",
    "    unique storm track\n",
    "    '''\n",
    "    storms = []\n",
    "    \n",
    "    # step through the year and make a dataframe for each storm\n",
    "    for storm in year_df.loc[:,\"Serial_Num\"].unique():\n",
    "        storms.append(year_df[year_df.loc[:, \"Serial_Num\"] == storm])\n",
    "        \n",
    "    return storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n",
      "draw hex grid on canvas!\n",
      "max of first: 252\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b767f8ae16f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstorm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstorms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorm_heat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mbig_x\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-8ca614075a80>\u001b[0m in \u001b[0;36mstorm_heat\u001b[0;34m(storm)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0m_strength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_strs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_strength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0m_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_long\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0m_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_lat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for super_year in range(100):\n",
    "    \n",
    "    # establish the range of years\n",
    "    _start = 1905 + super_year\n",
    "    _end = 1915 + super_year\n",
    "\n",
    "    # make a list of year dataframes for the range\n",
    "    years = get_data_as_yearlist(_start, _end)\n",
    "    \n",
    "    map_image = imread(\"../data/grey_blue_na_2.png\")\n",
    "\n",
    "    storms = []\n",
    "\n",
    "    big_x = []\n",
    "    big_y = []\n",
    "\n",
    "    # make a temp list to hold the storm dataframes from a single year\n",
    "    for _idx, year in enumerate(years):\n",
    "\n",
    "        storms = get_storms_from_year(year)\n",
    "\n",
    "        for storm in storms:\n",
    "\n",
    "            x, y = storm_heat(storm)\n",
    "\n",
    "            big_x += x\n",
    "            big_y += y\n",
    "\n",
    "        x = np.array(big_x)\n",
    "        y = np.array(big_y)\n",
    "\n",
    "    #     ax.clear()\n",
    "    _year = year.loc[:, \"Season\"].unique()[0]\n",
    "\n",
    "    # figure out what the year is    \n",
    "    _filename = \"heatmap{:0>3}\".format(super_year)\n",
    "\n",
    "    # establish the figure\n",
    "    fig = plt.figure(figsize=(19.2, 12.0), dpi=100)\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_facecolor(\"#000000\")\n",
    "    \n",
    "    ax.set_xlim(-110.0, -30.0)\n",
    "    ax.set_ylim(10, 50.0)\n",
    "\n",
    "    fig.subplots_adjust(0, 0, 1, 1)\n",
    "\n",
    "    # Draw the empty axis, which we use as a base.\n",
    "    fig.canvas.draw()\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    _buffer = np.frombuffer(fig.canvas.buffer_rgba(), np.uint8)\n",
    "    \n",
    "    # the first buffer which is used for the new track in color\n",
    "    first = _buffer.astype(np.int16).reshape(h, w, -1) #int16 so we dont overflow\n",
    "    first[first[:, :, -1] == 0] = 0 # Set transparent pixels to 0\n",
    "\n",
    "    print \"draw hex grid on canvas!\"\n",
    "    \n",
    "    ax.clear()  # maybe clear erases some of the axis settings, not just the canvas?\n",
    "    ax.set_xlim(-120.0, -30.0)\n",
    "    ax.set_ylim(10, 50.0)\n",
    "    ax.patch.set_facecolor('#000000')\n",
    "    \n",
    "    # apply the drawing to the axis so we can pull it out of the buffer in a bit\n",
    "    ax.hexbin(x, y, gridsize=(43, 21), bins=250, cmap=\"inferno\", extent=[-120, -30, 10, 50])\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    img = np.frombuffer(fig.canvas.buffer_rgba(), np.uint8).astype(np.int16).reshape(h, w, -1)\n",
    "    img[img[:, :, -1] == 0] = 0\n",
    "    first += img # Add these particles to the main layer\n",
    "\n",
    "    print \"max of first:\", first[:,:,0].max()\n",
    "    \n",
    "    first = np.clip(first, 0, 255) # clip buffer back into int8 range\n",
    "                        # wonder if some kind of exp transform\n",
    "                        # might enable hdr-like effect      \n",
    "\n",
    "    for a in range(first.shape[0]):\n",
    "        for b in range(first.shape[1]):\n",
    "            if first[a][b][0] <= 1 and first[a][b][1] <= 1 and first[a][b][2] <= 1:\n",
    "                first[a][b][3] = 0\n",
    "                \n",
    "                \n",
    "\n",
    "#             if ((first[a][b][0] + first[a][b][1] + first[a][b][2]) / 3.0) < 5.0 :\n",
    "#                 first[a][b][3] = 0.2\n",
    "                \n",
    "#             if ((first[a][b][0] + first[a][b][1] + first[a][b][2]) / 3.0) < 25.0 :\n",
    "#                 first[a][b][3] = 0.4\n",
    "                \n",
    "#             if ((first[a][b][0] + first[a][b][1] + first[a][b][2]) / 3.0) < 100.0 :\n",
    "#                 first[a][b][3] = 0.6\n",
    "\n",
    "    ax.clear()  # maybe clear erases some of the axis settings, not just the canvas?\n",
    "    ax.set_xlim(-120.0, -30.0)\n",
    "    ax.set_ylim(10, 50.0)\n",
    "#     ax.patch.set_facecolor('#000000')\n",
    "\n",
    "    ax.imshow(map_image, extent=[-120, -30, 10, 50], aspect=\"auto\")\n",
    "    ax.imshow(first.astype(np.uint8), extent=[-120, -30, 10, 50], aspect='auto', alpha=0.7)\n",
    "\n",
    "    ax.annotate(str(_year), xy=(-119, 48), size=40, color='#707070')\n",
    "\n",
    "    fig.savefig(\"../imgs/test/{}\".format(_filename), pad_inches=0, transparent=True)\n",
    "\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    del first, big_x, big_y, x, y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "draw hex grid on canvas!\n",
      "min of first: 0\n",
      "mean alpha before:255.0 after:10.1905351563\n",
      "draw hex grid on canvas!\n",
      "min of first: 0\n",
      "mean alpha before:255.0 after:10.1905351563\n"
     ]
    }
   ],
   "source": [
    "for super_year in range(100):\n",
    "    \n",
    "    # establish the range of years\n",
    "    _start = 1915\n",
    "    _end = _start + super_year\n",
    "    \n",
    "    if super_year > 1:\n",
    "        break\n",
    "\n",
    "    # make a list of year dataframes for the range\n",
    "    years = get_data_as_yearlist(_start, _end)\n",
    "    \n",
    "    map_image = imread(\"../data/grey_blue_na_2.png\")\n",
    "\n",
    "    storms = []\n",
    "\n",
    "    big_x = []\n",
    "    big_y = []\n",
    "\n",
    "    # make a temp list to hold the storm dataframes from a single year\n",
    "    for _idx, year in enumerate(years):\n",
    "\n",
    "        storms = get_storms_from_year(year)\n",
    "\n",
    "        for storm in storms:\n",
    "\n",
    "            x, y = storm_heat(storm)\n",
    "\n",
    "            big_x += x\n",
    "            big_y += y\n",
    "\n",
    "        x = np.array(big_x)\n",
    "        y = np.array(big_y)\n",
    "\n",
    "    #     ax.clear()\n",
    "    _year = year.loc[:, \"Season\"].unique()[0]\n",
    "\n",
    "    # figure out what the year is    \n",
    "    _filename = \"heatmap{:0>3}\".format(super_year)\n",
    "\n",
    "    # establish the figure\n",
    "    fig = plt.figure(figsize=(19.2, 12.0), dpi=100)\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_facecolor(\"#000000\")\n",
    "    \n",
    "    ax.set_xlim(-120.0, -30.0)\n",
    "    ax.set_ylim(10, 50.0)\n",
    "\n",
    "    fig.subplots_adjust(0, 0, 1, 1)\n",
    "\n",
    "    # Draw the empty axis, which we use as a base.\n",
    "    fig.canvas.draw()\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    _buffer = np.frombuffer(fig.canvas.buffer_rgba(), np.uint8)\n",
    "    \n",
    "    # the first buffer which is used for the new track in color\n",
    "    first = _buffer.astype(np.int16).reshape(h, w, -1) #int16 so we dont overflow\n",
    "    first[first[:, :, -1] == 0] = 0 # Set transparent pixels to 0\n",
    "\n",
    "    print \"draw hex grid on canvas!\"\n",
    "    \n",
    "    ax.clear()  # maybe clear erases some of the axis settings, not just the canvas?\n",
    "    ax.set_xlim(-120.0, -30.0)\n",
    "    ax.set_ylim(10, 50.0)\n",
    "    ax.patch.set_facecolor('#000000')\n",
    "    \n",
    "    # apply the drawing to the axis so we can pull it out of the buffer in a bit\n",
    "    ax.hexbin(x, y, gridsize=(60, 30), bins=50, cmap=\"inferno\", extent=[-120, -30, 10, 50])\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    img = np.frombuffer(fig.canvas.buffer_rgba(), np.uint8).astype(np.int16).reshape(h, w, -1)\n",
    "    img[img[:, :, -1] == 0] = 0\n",
    "    first += img # Add these particles to the main layer\n",
    "\n",
    "    print \"min of first:\", first[:,:,0].min()\n",
    "    \n",
    "    first = np.clip(first, 0, 255) # clip buffer back into int8 range\n",
    "                        # wonder if some kind of exp transform\n",
    "                        # might enable hdr-like effect   \n",
    "            \n",
    "    _before_mean = first[:,:,3].mean()\n",
    "\n",
    "    for a in range(first.shape[0]):\n",
    "        for b in range(first.shape[1]):\n",
    "            # too punishing except for on log scale\n",
    "#             first[a][b][3] = (first[a][b][0] + first[a][b][1] + first[a][b][2]) / 3.0\n",
    "            \n",
    "            if first[a][b][0] <= 5 and first[a][b][1] <= 5 and first[a][b][2] <= 5:\n",
    "                first[a][b][3] = 0\n",
    "\n",
    "            elif first[a][b][0] <= 15 and first[a][b][1] <= 15 and first[a][b][2] <= 15:\n",
    "                first[a][b][3] = 32\n",
    "                \n",
    "            elif first[a][b][0] <= 30 and first[a][b][1] <= 30 and first[a][b][2] <= 30:\n",
    "                first[a][b][3] = 64\n",
    "                \n",
    "            elif first[a][b][0] <= 45 and first[a][b][1] <= 45 and first[a][b][2] <= 45:\n",
    "                first[a][b][3] = 128\n",
    "    \n",
    "    _after_mean = first[:,:,3].mean()\n",
    "    \n",
    "    print \"mean alpha before:{} after:{}\".format(_before_mean, _after_mean)\n",
    "\n",
    "    ax.clear()  # maybe clear erases some of the axis settings, not just the canvas?\n",
    "    ax.set_xlim(-120.0, -30.0)\n",
    "    ax.set_ylim(10, 50.0)\n",
    "#     ax.patch.set_facecolor('#000000')\n",
    "\n",
    "    ax.imshow(map_image, extent=[-120, -30, 10, 50], aspect=\"auto\")\n",
    "    ax.imshow(first.astype(np.uint8), extent=[-120, -30, 10, 50], aspect='auto', alpha=0.6)\n",
    "\n",
    "    ax.annotate(str(_year), xy=(-119, 48), size=40, color='#707070')\n",
    "\n",
    "    fig.savefig(\"../imgs/test/small_heat/heat_{}\".format(_filename), pad_inches=0, transparent=True)\n",
    "\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    del first, big_x, big_y, x, y, _buffer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.29 4.80 2.42 2.58 3.56 2.66 3.31 3.87 2.47 2.12 4.13 3.27 1.81 4.56 2.48 4.65 1.52 3.07 3.01 2.37 1.28 3.00 3.10 2.44 2.98 0.69 3.97 3.83 2.82 3.88 3.16 2.76 2.39 2.40 4.65 5.10 3.49 2.85 2.50 2.23 2.76 3.02 1.98 3.43 2.53 2.27 2.31 1.30 1.95 3.99 5.62 3.35 2.53 4.68 3.76 2.04 3.18 2.50 4.99 6.24 4.16 3.63 2.95 3.38 3.77 4.03 3.94 2.45 1.21 2.64 2.68 0.96 5.37 4.24 2.44 3.35 4.31 4.57 2.69 3.70 4.20 3.08 2.03 4.51 2.90 3.60 2.18 4.53 3.25 2.96 4.89 5.02 3.12 3.57 2.90 3.17 2.78 3.35 5.20 2.75\n",
      "-0.572108760122 6.67424354767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([   2.,    4.,    3.,    3.,    6.,   10.,   23.,   27.,   39.,\n",
       "          39.,   78.,  108.,  121.,  176.,  204.,  232.,  281.,  325.,\n",
       "         358.,  421.,  507.,  495.,  536.,  596.,  562.,  568.,  536.,\n",
       "         568.,  518.,  440.,  411.,  361.,  278.,  255.,  210.,  172.,\n",
       "         139.,  118.,   65.,   66.,   40.,   38.,   20.,   17.,    6.,\n",
       "           7.,    6.,    1.,    3.,    1.]),\n",
       " array([-0.57210876, -0.42718171, -0.28225467, -0.13732762,  0.00759942,\n",
       "         0.15252647,  0.29745352,  0.44238056,  0.58730761,  0.73223466,\n",
       "         0.8771617 ,  1.02208875,  1.16701579,  1.31194284,  1.45686989,\n",
       "         1.60179693,  1.74672398,  1.89165102,  2.03657807,  2.18150512,\n",
       "         2.32643216,  2.47135921,  2.61628626,  2.7612133 ,  2.90614035,\n",
       "         3.05106739,  3.19599444,  3.34092149,  3.48584853,  3.63077558,\n",
       "         3.77570262,  3.92062967,  4.06555672,  4.21048376,  4.35541081,\n",
       "         4.50033786,  4.6452649 ,  4.79019195,  4.93511899,  5.08004604,\n",
       "         5.22497309,  5.36990013,  5.51482718,  5.65975422,  5.80468127,\n",
       "         5.94960832,  6.09453536,  6.23946241,  6.38438946,  6.5293165 ,\n",
       "         6.67424355]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7370307f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm_mu, norm_sigma = 3.0, 1.0\n",
    "\n",
    "\n",
    "distro = np.random.normal(norm_mu, norm_sigma, 10000)\n",
    "for item in distro[:100]:\n",
    "    print \"{:2.2f}\".format(item), \n",
    "    \n",
    "print\n",
    "print distro.min(), distro.max()\n",
    "fix, bx = plt.subplots()\n",
    "bx.hist(distro, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 9 3 10 5 4 10 4 8 6 6 7 2 6 8 3 9 5 10 7 7 4 4 11 6 4 6 3 5 1 1 3 5 6 2 1 3 11 3 5 4 1 9 3 10 5 5 9 9 1 3 1 6 9 6 5 8 1 2 1 9 5 7 1 6 1 5 4 2 10 2 6 1 8 2 11 8 8 11 8 1 5 8 1 8 3 8 4 6 4 6 5 4 3 11 2 11 2 10 3\n"
     ]
    }
   ],
   "source": [
    "for x in range(100):\n",
    "    print np.random.randint(1, 12),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_mu, norm_sigma = 1.0, 0.5\n",
    "np.random.normal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
